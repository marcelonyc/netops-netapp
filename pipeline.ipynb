{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E2E Serverless ML pipeline  - Ingest, Train, Auto Deploy Model\n",
    "  --------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "import nuclio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run set_env.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NetApp volume mounts definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "netapp_volume_mounts = {'mountPath': NETAPP_MOUNT_PATH, 'name': 'nfs-pvc'}\n",
    "netapp_volumes = {'name': 'nfs-pvc',\n",
    "                       'persistentVolumeClaim': {'claimName': NETAPP_PVC_CLAIM }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import new_function, code_to_function, NewTask, v3io_cred, new_model_server, mlconf, get_run_db, mount_v3io\n",
    "# for local DB path use 'User/mlrun' instead \n",
    "mlconf.dbpath = 'http://mlrun-api:8080'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pipeline\"></a>\n",
    "______________________________________________\n",
    "# Create a multi-stage KubeFlow Pipeline from our notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp import dsl\n",
    "from mlrun import new_project\n",
    "from kubernetes import client as k8sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**define the artifacts output path**\n",
    "the pipeline outputs will be writtento the artifacts path directory, the path can be a file path (require volume mounts) or an object path (v3io://, s3://, ..).\n",
    "\n",
    "if we specify `{{workflow.uid}}` in the path it will be replaced with the actual workflow ID, this way every workflow run will store artifacts in a unique location for reproducability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_TABLE=\"netops_features_parquet\"\n",
    "SAVE_TO=\"models\"\n",
    "metrics_table=\"netops_metrics_parquet\"\n",
    "features_table=\"netops_features_parquet\"\n",
    "PREDICTIONS_TABLE='netops_predictions'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define function to execute NetApp volume snap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "# Initialize the NetApp snap fucntion once for all functions in a notebook\n",
    "snapfn = code_to_function('snap',project='NetApp',kind='job',filename=\"snap.ipynb\").apply(mount_v3io())\n",
    "#.apply(mount_pvc('nfsvol', NETAPP_PVC_CLAIM, NETAPP_MOUNT_PATH))\n",
    "snapfn.spec.image = docker_registry + '/netapp/pipeline:latest'\n",
    "snapfn.spec.volume_mounts = [snapfn.spec.volume_mounts[0],netapp_volume_mounts]\n",
    "snapfn.spec.volumes = [ snapfn.spec.volumes[0],netapp_volumes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(snapfn.to_yaml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define function to explore feature metrics\n",
    "We retrieve the function code from a Git repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "describefn =  code_to_function(project='NetApp',kind='job',name='describe',filename='describe.py').apply(mount_v3io())\n",
    "describefn.spec.image = docker_registry + '/iguazio/netapp'\n",
    "\n",
    "### Mount NetApp volume\n",
    "describefn.spec.volume_mounts = [snapfn.spec.volume_mounts[0],netapp_volume_mounts]\n",
    "describefn.spec.volumes = [ snapfn.spec.volumes[0],netapp_volumes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build functions for model training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prep = code_to_function(project='NetApp',kind='job',name='data-prep',filename='data-prep.ipynb').apply(mount_v3io())\n",
    "data_prep.spec.image = docker_registry + '/iguazio/netapp'\n",
    "training  = code_to_function(project='NetApp',kind='job',name='training',filename='training.ipynb').apply(mount_v3io())\n",
    "training.spec.image = docker_registry + '/iguazio/netapp'\n",
    "deploy_inference = code_to_function(project='NetApp',kind='job',name='training',filename='deploy-inference-function.ipynb').apply(mount_v3io())\n",
    "deploy_inference.spec.image = docker_registry + '/iguazio/netapp'\n",
    "\n",
    "\n",
    "### Mount NetApp volume\n",
    "data_prep.spec.volume_mounts = [snapfn.spec.volume_mounts[0],netapp_volume_mounts]\n",
    "data_prep.spec.volumes = [ snapfn.spec.volumes[0],netapp_volumes]\n",
    "\n",
    "training.spec.volume_mounts = [snapfn.spec.volume_mounts[0],netapp_volume_mounts]\n",
    "training.spec.volumes = [ snapfn.spec.volumes[0],netapp_volumes]\n",
    "\n",
    "deploy_inference.spec.volume_mounts = [snapfn.spec.volume_mounts[0],netapp_volume_mounts]\n",
    "deploy_inference.spec.volumes = [ snapfn.spec.volumes[0],netapp_volumes]\n",
    "\n",
    "\n",
    "#.apply(mount_v3io())\n",
    "#.apply(mount_v3io(name='bigdata', remote='bigdata/',mount_path='/v3io/bigdata'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(training.to_yaml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={   \"FEATURES_TABLE\":FEATURES_TABLE,\n",
    "           \"SAVE_TO\" : SAVE_TO,\n",
    "           \"metrics_table\" : metrics_table,\n",
    "           'FROM_TSDB': 0,\n",
    "           'PREDICTIONS_TABLE': PREDICTIONS_TABLE,\n",
    "           'TRAIN_ON_LAST': '1d',\n",
    "           'TRAIN_SIZE':0.7,\n",
    "           'NUMBER_OF_SHARDS' : 4,\n",
    "           'MODEL_FILENAME' : 'netops.v3.model.pickle',\n",
    "           'APP_DIR' : APP_DIR,\n",
    "           'FUNCTION_NAME' : 'netops-inference',\n",
    "           'PROJECT_NAME' : 'netops',\n",
    "           'NETAPP_SIM' : NETAPP_SIM,\n",
    "           'NETAPP_MOUNT_PATH': NETAPP_MOUNT_PATH,\n",
    "           'NETAPP_PVC_CLAIM' : NETAPP_PVC_CLAIM,\n",
    "           'IGZ_CONTAINER_PATH' : IGZ_CONTAINER_PATH,\n",
    "           'IGZ_MOUNT_PATH' : IGZ_MOUNT_PATH\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**define a 4 step workflow with hyper-params**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name='NetOps trainign pipeline with NetApp volume cloning',\n",
    "    description='snap volume before training '\n",
    ")\n",
    "def xgb_pipeline(\n",
    "   ontapClusterMgmtHostname = '',\n",
    "   ontapClusterAdminUsername = '',\n",
    "   ontapClusterAdminPassword = '',\n",
    "   sourceVolumeName = ''\n",
    "):\n",
    "    snapshot = snapfn.as_step(NewTask(handler='handler',params={'ontapClusterMgmtHostname': ontapClusterMgmtHostname,\n",
    "                                                                  'ontapClusterAdminUsername': ontapClusterAdminUsername,\n",
    "                                                                 'ontapClusterAdminPassword': ontapClusterAdminPassword,\n",
    "                                                                  \"FEATURES_TABLE\":FEATURES_TABLE,\n",
    "                                                                 'sourceVolumeName': sourceVolumeName,'NETAPP_SIM' : NETAPP_SIM,\n",
    "                                                                  'NETAPP_MOUNT_PATH': NETAPP_MOUNT_PATH }),\n",
    "                            name='snap',outputs=['snapVolumeDetails','training_parquet_file']).apply(mount_v3io())\n",
    "    \n",
    "    describe = describefn.as_step(name='describe',handler=\"describe\",params={\"key\": \"summary\", \"label_column\": \"is_error\", 'class_labels': [0, 1]},\n",
    "                            inputs={\"table\": snap.outputs['training_parquet_file']},\n",
    "                            out_path=artifacts_path).apply(mount_v3io()).after(snaphot)\n",
    "    \n",
    "    prep = data_prep.as_step(name='data-prep', handler='handler',params=params,\n",
    "                          inputs = {'DATA_DIR': snap.outputs['snapVolumeDetails']} ,\n",
    "                          out_path=artifacts_path).apply(mount_v3io()).after(snap)\n",
    "\n",
    "    \n",
    "    train = training.as_step(name='xgb_train', handler='handler',params=params,\n",
    "                            out_path=artifacts_path).apply(mount_v3io()).after(prep)\n",
    "\n",
    "    \n",
    "    deploy = deploy_inference.as_step(name='deploy-model', handler='handler',params=params,                        \n",
    "                       out_path=artifacts_path).apply(mount_v3io()).after(train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a KubeFlow client and submit the pipeline with parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for debug generate the pipeline dsl\n",
    "kfp.compiler.Compiler().compile(xgb_pipeline, 'mlrunpipe.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = kfp.Client(namespace='default-tenant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"https://dashboard.default-tenant.app.mdl0216.iguazio-cd1.com/pipelines/#/experiments/details/fa75ef87-733d-4cc9-ae86-1217311a5062\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"https://dashboard.default-tenant.app.mdl0216.iguazio-cd1.com/pipelines/#/runs/details/93776a03-f5dc-42fd-93a1-772d3692eee9\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "arguments={'ontapClusterMgmtHostname': ontapClusterMgmtHostname,\n",
    "           'ontapClusterAdminUsername': ontapClusterAdminUsername,\n",
    "           'ontapClusterAdminPassword':ontapClusterAdminPassword,\n",
    "           'sourceVolumeName': sourceVolumeName\n",
    "            }\n",
    "run_result = client.create_run_from_pipeline_func(xgb_pipeline, arguments, experiment_name='NetAppXGB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[back to top](#top)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
